# Podcast Generator

An AI-driven podcast generation tool that creates professional audio podcasts from PDF documents in multiple languages.

## Features

- ğŸ” Automatically extracts key topics from PDFs
- ğŸ’¬ Generates engaging discussions between virtual hosts
- ğŸŒ Automatic translation to 9 different languages
- ğŸ™ï¸ High-quality text-to-speech conversion using Kokoro
- ğŸ­ Support for multiple LLM providers (Ollama, OpenAI, Anthropic, Groq)
- ğŸ“Š Detailed conversation exports with timestamps
- ğŸ“ Optional subtitle generation in SRT or VTT format
- ğŸµ Background music integration
- ğŸ”§ Customizable voices and audio settings

## Installation

```bash
# Clone the repository
git clone https://github.com/g-hano/PodcastAutomation.git
cd PodcastAutomation

# Install dependencies
pip install -r requirements.txt
```

## Configuration

Create a `config.yaml` file with the following structure:

```yaml
pdf_path: "path/to/your/document" # supports ANY file type, not only pdf
num_topics: 2
num_turns: 1
output_dir: "output"
export_conversation_json: true

models:
# Your model names MUST be in "<provider-name>/<model-name>" format
  topic_generator: "ollama/qwen2.5:14b"
  podcast_moderator: "ollama/llama3.1:8b"
  podcast_host: "ollama/llama3.1:8b"
  podcast_guest: "ollama/llama3.1:8b"
  intro_generator: "ollama/qwen2.5:14b"
  outro_generator: "ollama/llama3.1:8b"
  translator: "ollama/qwen2.5:14b"
  providers:
    openai_api_key: "sk-..."       # Your OpenAI API key
    anthropic_api_key: "sk-ant-..." # Your Anthropic API key
    groq_api_key: "gsk_..."         # Your Groq API key
    ollama_base_url: "http://localhost:11434"  # Default Ollama server URL

audio:
  lang: "e"  # Language codes: see Language Codes section below
  host_voice: "ef_dora"       # Voice name (see Available Voices section)
  moderator_voice: "em_alex" # Voice name
  guest_voice: "em_santa"    # Voice name
  output_file: "podcast.wav"
  chunk_size: 200
  music_path: "path/to/background/music"
  vocal_volume: 0  # in dB
  bg_intro_volume: -12  # optional
  bg_content_volume: -20  # optional
  bg_outro_volume: -12
  generate_subtitles: true   # Generate subtitle files
  subtitle_format: "srt"     # "srt" or "vtt"

logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/podcast_generator.log"
  verbose: true  # Show colored conversation in console during generation
```

### LLM Provider Configuration

You can specify the LLM provider for each model by using the format `provider/model_name`:

- `ollama/model_name` - Use Ollama with local models (default if no provider specified)
- `openai/model_name` - Use OpenAI API (requires API key)
- `anthropic/model_name` - Use Anthropic API (requires API key)
- `groq/model_name` - Use Groq API (requires API key)

Example model specifications:
```yaml
models:
  topic_generator: "ollama/qwen2.5:14b"
  podcast_moderator: "anthropic/claude-3-haiku-20240307"
  podcast_host: "openai/gpt-3.5-turbo"
  intro_generator: "groq/mixtral-8x7b-32768"
```

### Language Codes

The `lang` parameter in the audio configuration determines both the target language for translation and the TTS voice language:

- `a`: American English (default)
- `b`: British English
- `j`: Japanese
- `h`: Hindi
- `p`: Portuguese
- `z`: Chinese (Mandarin)
- `i`: Italian
- `f`: French
- `e`: Spanish

### Export and Subtitle Options

```yaml
export_conversation_json: true  # Export detailed conversation data with timestamps

audio:
  generate_subtitles: true   # Generate subtitle files
  subtitle_format: "srt"     # "srt" or "vtt"
```

## Usage

### Basic Usage

```bash
python -m src.cli --config config.yaml
```

### Additional Options

```bash
# Specify PDF file
python -m src.cli --config config.yaml --pdf path/to/document.pdf

# Set output directory
python -m src.cli --config config.yaml --output-dir podcasts/my_podcast

# Set number of topics and turns
python -m src.cli --config config.yaml --topics 3 --turns 4

# Skip specific stages
python -m src.cli --config config.yaml --skip-translation --skip-audio

# Set logging options
python -m src.cli --config config.yaml --log-level DEBUG --log-file custom_log.log
```

## Export Formats

### Conversation JSON

When `export_conversation_json` is enabled, a detailed JSON file with all conversation data is generated:

```json
{
  "metadata": {
    "timestamp": "2023-03-15T14:22:33.123456",
    "document_path": "path/to/document.pdf",
    "title": "Podcast Title",
    "description": "Podcast description..."
  },
  "intro": "Welcome to our podcast...",
  "conversations": {
    "Topic 1": [
      {
        "speaker": "Moderator",
        "content": "What do you think about...",
        "start_time": "2023-03-15T14:22:40.123456",
        "end_time": "2023-03-15T14:22:45.123456",
        "duration_seconds": 5.0,
        "turn": 0
      },
      {
        "speaker": "Guest",
        "content": "Well, I think...",
        "start_time": "2023-03-15T14:22:46.123456",
        "end_time": "2023-03-15T14:22:52.123456",
        "duration_seconds": 6.0,
        "turn": 1
      }
    ]
  },
  "outro": "Thanks for listening..."
}
```

### Subtitle Files

When `generate_subtitles` is enabled, subtitle files are generated in either SRT or VTT format:

#### SRT Example
```
1
00:00:00,000 --> 00:00:30,000
Host: Welcome to our podcast...

2
00:00:30,000 --> 00:00:32,000
Topic: First Topic

3
00:00:32,000 --> 00:00:37,000
Moderator: What do you think about...
```

#### VTT Example
```
WEBVTT

00:00:00.000 --> 00:00:30.000
Host: Welcome to our podcast...

00:00:30.000 --> 00:00:32.000
Topic: First Topic

00:00:32.000 --> 00:00:37.000
Moderator: What do you think about...
```

## License

MIT License

